{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "91dc9831-72a8-45d8-9171-c8b78480f091",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType\n",
    "from pyspark.sql.functions import col, when, avg, count, rand, lit, round as spark_round\n",
    "\n",
    "# Define Schema\n",
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"score\", FloatType(), True),\n",
    "    StructField(\"city\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Sample data\n",
    "data = [\n",
    "    (1, \"Alice\", 23, 88.5, \"New York\"),\n",
    "    (2, \"Bob\", 31, 76.0, \"Los Angeles\"),\n",
    "    (3, \"Charlie\", 29, 92.3, \"Chicago\"),\n",
    "    (4, \"David\", 35, 67.8, \"Houston\"),\n",
    "    (5, \"Eva\", 22, 81.2, \"Phoenix\"),\n",
    "    (6, \"Frank\", 28, 73.4, \"Philadelphia\"),\n",
    "    (7, \"Grace\", 27, 89.1, \"San Antonio\"),\n",
    "    (8, \"Helen\", 24, 95.0, \"San Diego\"),\n",
    "    (9, \"Ian\", 30, 78.6, \"Dallas\"),\n",
    "    (10, \"Jane\", 26, 85.7, \"San Jose\")\n",
    "]\n",
    "\n",
    "# Create dataFrame\n",
    "df = spark.createDataFrame(data, schema)\n",
    "\n",
    "# Add a random bonus column\n",
    "df = df.withColumn(\"bonus\", spark_round(rand() * 10, 2))\n",
    "\n",
    "# Categorize age groups\n",
    "df = df.withColumn(\n",
    "    \"age_group\",\n",
    "    when(col(\"age\") < 25, \"Young\")\n",
    "    .when((col(\"age\") >= 25) & (col(\"age\") < 30), \"Adult\")\n",
    "    .otherwise(\"Senior\")\n",
    ")\n",
    "\n",
    "# Calculate adjusted score\n",
    "df = df.withColumn(\"adjusted_score\", spark_round(col(\"score\") + col(\"bonus\"), 2))\n",
    "\n",
    "# Filter for high performers\n",
    "high_performers = df.filter(col(\"adjusted_score\") > 90)\n",
    "\n",
    "# Group by city and get average adjusted score\n",
    "city_avg = df.groupBy(\"city\").agg(\n",
    "    avg(\"adjusted_score\").alias(\"avg_adjusted_score\"),\n",
    "    count(\"*\").alias(\"num_people\")\n",
    ")\n",
    "\n",
    "# Join high performers with city averages\n",
    "joined = high_performers.join(city_avg, \"city\", \"left\")\n",
    "\n",
    "# Add a flag for cities with more than 1 person\n",
    "joined = joined.withColumn(\n",
    "    \"large_city\",\n",
    "    when(col(\"num_people\") > 1, lit(True)).otherwise(lit(False))\n",
    ")\n",
    "\n",
    "# Select and order columns\n",
    "final = joined.select(\n",
    "    \"id\", \"name\", \"city\", \"adjusted_score\", \"avg_adjusted_score\", \"large_city\"\n",
    ").orderBy(col(\"adjusted_score\").desc())\n",
    "\n",
    "display(final)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "player_score",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
